# GloVe-Embeddings-NLP-Vectorization-Pipeline
A complete NLP pipeline using GloVe embeddings. Includes text cleaning, tokenization, vocabulary building, loading pre-trained GloVe vectors, handling OOV words, and creating an embedding matrix for deep-learning models. Demonstrates clear conceptual understanding of classical word embeddings.
This is an end-to-end project demonstrating how to use GloVe (Global Vectors) for text vectorization ‚Äî one of the foundational concepts in Natural Language Processing.

üîçTakeaways and learning:

Text cleaning & preprocessing

Tokenization using NLTK and Keras

Loading pre-trained GloVe vectors

Mapping words to embeddings

Handling punctuation & OOV words

Building an embedding matrix for neural networks

üí° This project helped me understand how classical word embeddings work before modern transformer models like BERT and GPT.
